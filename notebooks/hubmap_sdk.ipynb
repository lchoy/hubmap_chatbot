{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hubmap-sdk in /Users/wangl/mambaforge/envs/hubmap_chatbot/lib/python3.8/site-packages (1.0.3)\n",
      "Requirement already satisfied: certifi==2021.10.8 in /Users/wangl/mambaforge/envs/hubmap_chatbot/lib/python3.8/site-packages (from hubmap-sdk) (2021.10.8)\n",
      "Requirement already satisfied: chardet==4.0.0 in /Users/wangl/mambaforge/envs/hubmap_chatbot/lib/python3.8/site-packages (from hubmap-sdk) (4.0.0)\n",
      "Requirement already satisfied: idna==2.10 in /Users/wangl/mambaforge/envs/hubmap_chatbot/lib/python3.8/site-packages (from hubmap-sdk) (2.10)\n",
      "Requirement already satisfied: requests>=2.22.0 in /Users/wangl/mambaforge/envs/hubmap_chatbot/lib/python3.8/site-packages (from hubmap-sdk) (2.31.0)\n",
      "Requirement already satisfied: urllib3==1.26.7 in /Users/wangl/mambaforge/envs/hubmap_chatbot/lib/python3.8/site-packages (from hubmap-sdk) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wangl/mambaforge/envs/hubmap_chatbot/lib/python3.8/site-packages (from requests>=2.22.0->hubmap-sdk) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install hubmap-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hubmap_sdk import SearchSdk\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# #In this example, the token and service url are being retrieved from a configuration file.\n",
    "# url = app.config['DEV_URL']\n",
    "# token = app.config['GLOBUS_TOKEN'] \n",
    "\n",
    "service_url = \"https://search.api.hubmapconsortium.org/v3/\"\n",
    "\n",
    "search_instance = SearchSdk(service_url=service_url)\n",
    "# search_instance = SearchSdk(token, url)\n",
    "searchsdk_instance = search_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entities', 'portal', 'hm_antibodies', 'files']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_indices = searchsdk_instance.indices()\n",
    "list_of_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# searchbody = {\n",
    "#   \"size\": 0,\n",
    "#   \"aggs\": {\n",
    "#     \"field_values\": {\n",
    "#       \"terms\": {\n",
    "#         \"field\": \"entity_type\",\n",
    "#         \"size\": 10000\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "searchbody = {\n",
    "  \"aggs\": {\n",
    "    \"created_by_user_displayname\": {\n",
    "      \"filter\": {\n",
    "        \"term\": {\n",
    "          \"death_event.keyword\": \"Motor\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"_source\": []\n",
    "}\n",
    "search_result = searchsdk_instance.search_by_index(searchbody, \"portal\")\n",
    "search_result\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"search_result3.json\", \"w\") as f:\n",
    "    f.write(json.dumps(search_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "searchbody = {\n",
    "#   \"query\": {\n",
    "#     \"simple_query_string\": {\n",
    "#       \"query\": \"blunt\",\n",
    "#       \"fields\": [\"donor.*\"],\n",
    "#       \"lenient\": True,\n",
    "#     }\n",
    "#   },\n",
    "#   \"query\": {\n",
    "#     \"match_all\": {}\n",
    "#   },\n",
    "    \"query\": {\n",
    "        # \"match_all\": {},\n",
    "\n",
    "        # \"bool\": {\n",
    "        #     \"filter\": [\n",
    "        #         {\"term\": {\"entity_type\": \"Donor\"}},\n",
    "        #     ],\n",
    "        # },\n",
    "        \"function_score\": {\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"entity_type\": \"Dataset\"\n",
    "                }\n",
    "            },\n",
    "            \"random_score\": {\n",
    "                \"seed\": 10\n",
    "            }\n",
    "        },\n",
    "\n",
    "    },\n",
    "# \"aggs\": {\n",
    "#     \"entity_type\": {\n",
    "#       \"terms\": { \"field\": \"entity_type\" }\n",
    "#     }\n",
    "#   },\n",
    "#   \"fields\": [\n",
    "# #   \"_source\": [\n",
    "#     \"hubmap_id\",\n",
    "#     \"group_name\",\n",
    "#     \"mapped_data_types\",\n",
    "#     \"origin_samples.mapped_organ\",\n",
    "#     \"mapped_status\",\n",
    "#     \"mapped_last_modified_timestamp\",\n",
    "#     \"last_modified_timestamp\",\n",
    "#     \"descendant_counts.entity_type\",\n",
    "#     \"thumbnail_file.file_uuid\",\n",
    "#     \"uuid\",\n",
    "#     \"donor\"\n",
    "#   ],\n",
    "  \"_source\": {\n",
    "    \"excludes\": [ \n",
    "        \"ancestors\",\n",
    "        \"descendants\",\n",
    "        \"immediate_ancestors\",\n",
    "        \"immediate_descendants\",\n",
    "        \"metadata\",\n",
    "        \"donor.metadata\"\n",
    "    ],\n",
    "    # \"includes\": [\n",
    "    #     \"hubmap_id\",\n",
    "    #     \"entity_type\",\n",
    "    # ]\n",
    "  },\n",
    "  \"size\": 100,\n",
    "}\n",
    "search_result = searchsdk_instance.search_by_index(searchbody, \"portal\")\n",
    "with open(\"search_result6.json\", \"w\") as f:\n",
    "    f.write(json.dumps(search_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_example_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# iterate recursively through the json structure\n",
    "# keys should be like \"hits.hits.n._source.donor.mapped_metadata.age_value\"\n",
    "\n",
    "def get_field_example_dict(json_obj, field_example_dict, prefix=\"\"):\n",
    "    if isinstance(json_obj, dict):\n",
    "        for key in json_obj:\n",
    "            if prefix == \"\":\n",
    "                new_prefix = key\n",
    "            else:\n",
    "                new_prefix = prefix + \".\" + key\n",
    "            get_field_example_dict(json_obj[key], field_example_dict, new_prefix)\n",
    "    elif isinstance(json_obj, list):\n",
    "        for i, item in enumerate(json_obj):\n",
    "            new_prefix = prefix + \"[n]\"\n",
    "            get_field_example_dict(item, field_example_dict, new_prefix)\n",
    "    else:\n",
    "        field_example_dict[prefix][json_obj] += 1\n",
    "\n",
    "\n",
    "# get_field_example_dict(search_result, field_example_dict)\n",
    "for hit in search_result[\"hits\"][\"hits\"]:\n",
    "    get_field_example_dict(hit[\"_source\"], field_example_dict)\n",
    "\n",
    "field_example_dict_of_list = {k: v for k, v in field_example_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"es_field_samples_dataset.json\", \"w\") as f:\n",
    "    f.write(json.dumps(field_example_dict_of_list, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "searchbody = {\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"provider_info\": \"Stanford\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"entity_type\": \"Dataset\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"_source\": {\n",
    "    \"excludes\": [ \n",
    "        \"ancestors\",\n",
    "        \"descendants\",\n",
    "        \"immediate_ancestors\",\n",
    "        \"immediate_descendants\",\n",
    "        \"metadata\",\n",
    "        \"donor.metadata\"\n",
    "    ],\n",
    "    \"includes\": [\n",
    "        \"donor.mapped_metadata.death_event\",\n",
    "        \"donor.mapped_metadata.mechanism_of_injury\",\n",
    "        \"donor.mapped_metadata.sex\",\n",
    "        \"donor.mapped_metadata.age_value\",\n",
    "        \"donor.mapped_metadata.race\",\n",
    "        \"provider_info\",\n",
    "        # \"files.type\",\n",
    "        # \"source_samples.created_by_user_email\",\n",
    "        \"donor.mapped_metadata.medical_history\"\n",
    "    ]\n",
    "  },\n",
    "    \"size\": 100,\n",
    "}\n",
    "search_result = searchsdk_instance.search_by_index(searchbody, \"portal\")\n",
    "with open(\"search_result8.json\", \"w\") as f:\n",
    "    f.write(json.dumps(search_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.api.hubmapconsortium.org/v3/portal/_mapping\n"
     ]
    }
   ],
   "source": [
    "print(f\"{service_url}portal/_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": \"Unable to find the requested resource\"}"
     ]
    }
   ],
   "source": [
    "!curl -X GET https://search.api.hubmapconsortium.org/v3/portal/_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: main:4c9125a, elasticsearch_connection: True, elasticsearch_status: green, version: 3.2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'build': 'main:4c9125a',\n",
       " 'elasticsearch_connection': True,\n",
       " 'elasticsearch_status': 'green',\n",
       " 'version': '3.2.0'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_object = search_instance.status()\n",
    "status_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_shards', 'hits', 'timed_out', 'took'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "url = \"https://portal.hubmapconsortium.org/browse/dataset/2107df00633f703d39e1ec74c271a9e5\"\n",
    "\n",
    "webbrowser.open(url, new=0, autoraise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hits: 3902\n",
      "Unique Fields: {'anatomy_1', 'protocol_url', 'mapped_organ', 'next_revision_uuid', 'mapped_last_modified_timestamp', 'data_access_level', 'created_by_user_email', 'mapped_status', 'donor', 'status', 'sample_category', 'anatomy_2', 'contributors', 'description', 'group_uuid', 'files', 'hubmap_id', 'entity_type', 'index_version', 'lab_tissue_sample_id', 'organ', 'previous_revision_uuid', 'rui_location', 'label', 'created_timestamp', 'doi_url', 'lab_dataset_id', 'lab_donor_id', 'descendant_counts', 'mapper_metadata', 'mapped_sample_category', 'display_subtype', 'immediate_descendants', 'last_modified_timestamp', 'registered_doi', 'data_types', 'immediate_ancestors', 'origin_samples_unique_mapped_organs', 'source_samples', 'group_name', 'thumbnail_file', 'datasets', 'mapped_metadata', 'creators', 'ancestor_counts', 'mapped_data_types', 'created_by_user_displayname', 'uuid', 'portal_metadata_upload_files', 'descendant_ids', 'contains_human_genetic_sequences', 'mapped_data_access_level', 'anatomy_3', 'ancestor_ids', 'provider_info', 'submission_id', 'visualization', 'dataset_info', 'mapped_consortium', 'origin_samples', 'tissue_type', 'published_timestamp', 'anatomy_0', 'contacts', 'title'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the Elasticsearch response from result.json\n",
    "with open(\"search_result5.json\", \"r\") as file:\n",
    "    response = json.load(file)\n",
    "\n",
    "# Extract relevant information from the response\n",
    "hits = response[\"hits\"][\"hits\"]\n",
    "total_hits = response[\"hits\"][\"total\"][\"value\"]\n",
    "unique_fields = set()\n",
    "\n",
    "# Analyze each hit to gather unique field names\n",
    "for hit in hits:\n",
    "    fields = hit[\"_source\"].keys()\n",
    "    unique_fields.update(fields)\n",
    "\n",
    "# Print the total number of hits and unique field names\n",
    "print(f\"Total Hits: {total_hits}\")\n",
    "print(f\"Unique Fields: {unique_fields}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'cup', 'headphones']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# apple, banana, pear, cup, keyboard, mouse\n",
    "objects = [\n",
    "    # \"apple\", \n",
    "    \"banana\", \n",
    "    # \"pear\", \n",
    "    \"cup\", \n",
    "    # \"keyboard\", \n",
    "    \"headphones\"\n",
    "    ]\n",
    "\n",
    "# shuffled\n",
    "random.shuffle(objects)\n",
    "\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubmap_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
